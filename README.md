
![Dashboard Screenshot](assets/dashboard_1.png)

---

# AI and Medical Empathy for Ethical Shared Decision-Making Project
**Capstone Project – Master of Bioethics, Harvard Medical School**

**Mentee:** Sydney Collins  
**Mentor:** Litong Jiang

---

## Overview

The AI and Medical Empathy for Ethical Shared Decision-Making Project is the capstone research project of the Master of Bioethics Program at Harvard Medical School. Rooted in the core principles of bioethics, this initiative investigates how artificial intelligence (AI) can be ethically leveraged to enhance clinical decision-making by integrating patient values, life goals, and cultural identities into personalized care pathways.

This project aims to bridge the divide between cutting-edge AI technologies and the ethical imperatives of human-centered medicine. By promoting shared decision-making that honors autonomy, dignity, informed consent, and contextual sensitivity, we seek to advance a model of care where technological innovation supports, rather than replaces, the moral agency of patients and clinicians.

---

## Project Objectives

AI as a Bioethics Research Tool: Utilize large language models (LLMs) to investigate and model ethical reasoning in clinical settings, positioning AI not only as a subject of ethical scrutiny, but also as a methodological instrument for advancing bioethics research itself.

Value-Sensitive Clinical Modeling: Explore how LLMs can simulate ethically complex patient-clinician interactions, helping scholars and clinicians analyze how career aspirations, religious beliefs, cultural identities, and life goals influence ethical medical decision-making.

Empirical Bioethical Inquiry: Use AI tools to systematically study key principles of bioethics in practice:

Autonomy: How do patients understand and articulate their choices with LLM assistance?

Beneficence & Nonmaleficence: Can LLMs help identify ethical dilemmas where treatments may have conflicting outcomes?

Justice: Investigate how LLMs might reveal or reproduce disparities in care access, and how they might be redesigned for equity.

Prototype as Research Instrument: Build a proof-of-concept LLM-based tool that serves as a research platform—not merely a product—enabling empirical and conceptual exploration of ethical challenges in modern medical decision-making.

---

## Key Features

Bioethics-Driven Use of AI: Leverage large language models (LLMs) as instruments to explore and test bioethical concepts—focusing on how AI can model ethical reasoning, illuminate value conflicts, and simulate diverse clinical narratives for research purposes.

Contextualized Ethical Simulation: Construct ethically complex patient scenarios—incorporating variables such as cultural background, personal values, and social determinants of health—to support empirical bioethics inquiry in simulated clinical settings.

Theoretical Integration: Operationalize frameworks from principlism, care ethics, and narrative bioethics within LLM-driven simulations to examine how these theories perform in practice and guide decision-making.

Synthetic Case Methodology: Develop and analyze privacy-preserving synthetic patient profiles to ethically study edge cases, trade-offs, and biases in medical decision-making—without exposing real patient data.

- Ethics Research, Not Just Tool Design: Rather than building AI for deployment, the project prioritizes the use of AI as a reflective space for ethical analysis, offering a novel methodology for contemporary bioethics research.
---

## Bioethics Foundations

This project is grounded in **core bioethical principles** and **theoretical frameworks**, will include:

- **Principlism** (Beauchamp and Childress): Autonomy, Beneficence, Nonmaleficence, Justice.
- **Narrative Ethics**: Understanding patients' stories to shape ethical clinical choices.
- **Relational Autonomy**: Recognizing that decisions are made within social and cultural contexts.
- **Care Ethics**: Emphasizing empathy, responsiveness, and attentiveness in medical AI.
- **Justice in Health AI**: Addressing concerns of bias, fairness, and equitable access in algorithmic systems.

We also explore contemporary ethical issues in the next step, such as:
- **Algorithmic Transparency** and **Explainability**.
- **Data Privacy** and **Informed Consent** in AI applications.
- **Responsibility Attribution** in AI-driven decisions.

---

## Academic Context

This capstone reflects the **interdisciplinary nature** of modern bioethics, integrating insights from:

- **Medical Ethics and Humanities**
- **Artificial Intelligence & Data Science**
- **Clinical Medicine & Patient Care**
- **Health Policy, Law, and Technology Regulation**

It is conducted under the mentorship at **Harvard Medical School**, contributing to ongoing discussions on the **ethical deployment of AI in healthcare**.

---

## Collaboration

We welcome **academic engagement** and ethical discourse with:

- **Bioethics scholars** investigating AI, technology, and healthcare.
- **Clinicians** exploring patient-centered, ethically grounded AI tools.
- **AI researchers** committed to humanistic and responsible innovation.
- **Students** examining **shared decision-making** and value-based care models.

---

## Future Plan
Looking ahead, our primary goal is to advance bioethics as an empirical and conceptual discipline by continuing to explore how AI—particularly large language models—can serve as research instruments for ethical inquiry in healthcare.

Expand Ethical Case Libraries: We plan to build a diverse corpus of synthetic clinical narratives representing ethically complex situations across cultures, age groups, and belief systems, allowing for systematic exploration of moral reasoning in different contexts.

Evaluate Ethical Theories in Practice: Future studies will use AI-generated simulations to test the practical implications of bioethical frameworks—such as principlism, care ethics, and virtue ethics—by observing how these models shape decisions across varying patient stories.

Collaborate with Bioethicists and Clinicians: We aim to deepen interdisciplinary dialogue by partnering with clinical ethicists, philosophers, and frontline practitioners to refine AI-assisted methods for ethical analysis, ensuring the research remains grounded in real-world complexity.

Develop Ethical Reasoning Benchmarks: Instead of focusing on performance metrics common in AI development, we will define and test qualitative standards for ethical reasoning, enabling AI tools to be evaluated as platforms for moral reflection rather than decision automation.

Publish Methodologies for AI-Augmented Bioethics: As a research contribution, we will document and share protocols, challenges, and best practices for using LLMs in the study—not the automation—of ethics, offering new paradigms for how technology can enrich the field of bioethics.

---
