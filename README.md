
![Dashboard Screenshot](assets/dashboard_1.png)

---

# AI and Medical Empathy for Ethical Shared Decision-Making  
**Capstone Project â€“ Master of Bioethics, Harvard Medical School**

**Mentee:** Sydney Collins  
**Mentor:** Litong Jiang

---

## Overview

**Empathy-AI** is a capstone research project developed as part of the **Master of Bioethics Program at Harvard Medical School**. This academic initiative explores how **artificial intelligence (AI)** can ethically support clinical decision-making by integrating **patient values**, **life goals**, and **cultural backgrounds** into treatment recommendations.

Our goal is to bridge the gap between **emerging AI technologies** and **human-centered care**, promoting **shared decision-making** that respects **autonomy**, **dignity**, and **individualized needs** in complex healthcare environments.

---

## Project Objectives

- **Ethical AI Integration**: Investigate the use of **large language models (LLMs)** in developing **value-sensitive** clinical decision support tools.
- **Patient-Centered Decision Support**: Design AI systems that honor **career aspirations**, **religious beliefs**, **cultural identities**, and **personal life trajectories**.
- **Bioethical Analysis**: Critically examine the ethical dimensions of AI in medicine, focusing on:
  - **Autonomy**: Supporting informed, voluntary patient choices.
  - **Beneficence & Nonmaleficence**: Enhancing well-being while avoiding harm through AI-assisted care.
  - **Justice**: Addressing equity and access in AI-driven clinical environments.
- **Prototype Development**: Create a functional **proof-of-concept** that illustrates AI's role in ethically nuanced medical scenarios.

---

## Key Features

- **Value-Sensitive AI Models**: Tailor recommendations through individualized patient narratives and **contextual ethics**.
- **Ethics-Informed Design**: Embed principles from **principlism**, **care ethics**, and **narrative bioethics** in system architecture.
- **Synthetic Patient Data**: Utilize privacy-respecting synthetic cases for ethical AI development and testing.
- **FHIR-Compatible Outputs**: Ensure interoperability with **healthcare data standards** for real-world applicability.

---

## Bioethics Foundations

This project is grounded in **core bioethical principles** and **theoretical frameworks**, including:

- **Principlism** (Beauchamp and Childress): Autonomy, Beneficence, Nonmaleficence, Justice.
- **Narrative Ethics**: Understanding patients' stories to shape ethical clinical choices.
- **Relational Autonomy**: Recognizing that decisions are made within social and cultural contexts.
- **Care Ethics**: Emphasizing empathy, responsiveness, and attentiveness in medical AI.
- **Justice in Health AI**: Addressing concerns of bias, fairness, and equitable access in algorithmic systems.

We also explore contemporary ethical issues, such as:
- **Algorithmic Transparency** and **Explainability**.
- **Data Privacy** and **Informed Consent** in AI applications.
- **Responsibility Attribution** in AI-driven decisions.

---

## Academic Context

This capstone reflects the **interdisciplinary nature** of modern bioethics, integrating insights from:

- **Medical Ethics and Humanities**
- **Artificial Intelligence & Data Science**
- **Clinical Medicine & Patient Care**
- **Health Policy, Law, and Technology Regulation**

It is conducted under the mentorship of faculty at **Harvard Medical School**, contributing to ongoing discussions on the **ethical deployment of AI in healthcare**.

---

## Collaboration

We welcome **academic engagement** and ethical discourse with:

- **Bioethics scholars** investigating AI, technology, and healthcare.
- **Clinicians** exploring patient-centered, ethically grounded AI tools.
- **AI researchers** committed to humanistic and responsible innovation.
- **Students** examining **shared decision-making** and value-based care models.

---
